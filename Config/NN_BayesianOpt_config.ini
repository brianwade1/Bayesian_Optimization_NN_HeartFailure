[architecture]
hidden_nodes = 20, 15, 5

[training]
max_epochs =  200 
batch_size = 8
train_fun = adam
learning_rate = 1e-3
learning_rate_min = 1e-5
learning_rate_scheduler = no_lr_sched
loss = binary_crossentropy
metrics = accuracy
patience = 5
min_delta = 1e-6
shuffle = False
decay_rate = 0.90
num_decays_during_training = 10
verbose = 0

[program]
seed = 42

[data]
training_size = 0.80
val_size = 0.1
data_folder = Data
data_file = heart_cleaned.csv

[optimization_ranges]
lr_low = 1e-4
lr_high = 1e-2
num_hiddenlayers_low = 1
num_hiddenlayers_high = 3
num_Layer1_nodes_low = 5
num_Layer1_nodes_high = 20
num_Layer2_nodes_low = 5
num_Layer2_nodes_high = 20
num_Layer3_nodes_low = 5
num_Layer3_nodes_high = 20
batch_size_low = 8
batch_size_high = 64
train_fun_cats = adam, rmsp
lr_decay_low = 0.5
lr_decay_high = 0.9
num_decays_during_training_cats = 5, 10, 15, 30
learning_rate_scheduler_cats = cosine_annealing_linear, cosine_annealing, linear_lr_dec, lr_step_power_scheduler, no_lr_sched

[optimization]
continue_tng = False
n_calls = 60
n_initial_points = 10
noise = 0.01
n_jobs = -1
kappa = 5
eval_metric = accuracy
eval_dataset = validation
